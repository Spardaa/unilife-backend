"""
Smart Scheduler Agent - æ™ºèƒ½æ—¥ç¨‹è°ƒåº¦åŠ©æ‰‹
æ£€æµ‹ä¸åˆç†çš„äº‹ä»¶ç»„åˆï¼Œæä¾›ç²¾åŠ›ä¼˜åŒ–å»ºè®®
"""
from typing import Dict, Any, List, Optional
from datetime import datetime
from app.services.llm import llm_service


class SmartSchedulerAgent:
    """æ™ºèƒ½æ—¥ç¨‹è°ƒåº¦ Agent"""

    def __init__(self):
        self.name = "smart_scheduler_agent"
        self.llm = llm_service

    async def analyze_schedule(
        self,
        events: List[Dict[str, Any]],
        user_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        åˆ†ææ—¥ç¨‹å®‰æ’çš„åˆç†æ€§

        Args:
            events: äº‹ä»¶åˆ—è¡¨ï¼ˆæ¯ä¸ªäº‹ä»¶åŒ…å« energy_consumption ä¿¡æ¯ï¼‰
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆåå¥½ã€ä¹ æƒ¯ç­‰ï¼‰

        Returns:
            åˆ†æç»“æœå’Œå»ºè®®
        """
        # æ„å»ºåˆ†æ prompt
        prompt = self._build_analysis_prompt(events, user_context)

        # è°ƒç”¨ LLM
        messages = [{"role": "user", "content": prompt}]
        llm_response = await self.llm.chat_completion(
            messages=messages,
            temperature=0.3
        )

        # è·å–å†…å®¹
        response = llm_response.get("content", "")

        # è§£æå“åº”
        analysis = self._parse_analysis(response)

        return analysis

    def _build_analysis_prompt(
        self,
        events: List[Dict[str, Any]],
        user_context: Optional[Dict[str, Any]]
    ) -> str:
        """æ„å»ºåˆ†æ prompt"""

        # æ ¼å¼åŒ–äº‹ä»¶åˆ—è¡¨
        events_str = ""
        for i, event in enumerate(events, 1):
            title = event.get("title", "æœªçŸ¥")
            time_info = event.get("start_time", "æœªçŸ¥æ—¶é—´")

            # è·å–ç²¾åŠ›æ¶ˆè€—ä¿¡æ¯
            energy = event.get("energy_consumption")
            if energy:
                physical = energy["physical"]
                mental = energy["mental"]
                energy_str = f"  ä½“åŠ›: {physical['level']}({physical['score']}åˆ†) - {physical['description']}\n"
                energy_str += f"  ç²¾ç¥: {mental['level']}({mental['score']}åˆ†) - {mental['description']}"
            else:
                energy_str = "  ç²¾åŠ›æ¶ˆè€—: æœªè¯„ä¼°"

            events_str += f"\n[äº‹ä»¶{i}] {title}\n"
            events_str += f"  æ—¶é—´: {time_info}\n"
            events_str += f"{energy_str}\n"

        # ç”¨æˆ·åå¥½ï¼ˆå¦‚æœæœ‰ï¼‰
        preferences_str = ""
        if user_context and "preferences" in user_context:
            prefs = user_context["preferences"]
            preferences_str = f"""
ç”¨æˆ·åå¥½ï¼š
- ç²¾åŠ›ç®¡ç†æ¨¡å¼ï¼š{prefs.get('energy_mode', 'å¹³è¡¡')}
- å·¥ä½œèŠ‚å¥ï¼š{prefs.get('work_rhythm', 'æœªçŸ¥')}
- ä¼‘æ¯åå¥½ï¼š{prefs.get('break_preference', 'æœªçŸ¥')}
"""

        prompt = f"""ä½ æ˜¯æ—¥ç¨‹ä¼˜åŒ–ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹è¿ç»­äº‹ä»¶çš„ä½“åŠ›/ç²¾ç¥åˆ†é…æ˜¯å¦åˆç†ã€‚

äº‹ä»¶åˆ—è¡¨ï¼š
{events_str}
{preferences_str}

è¯·æ£€æŸ¥ä»¥ä¸‹é—®é¢˜ï¼š

1. **è¿ç»­é«˜å¼ºåº¦ä½“åŠ›æ¶ˆè€—**
   - æ˜¯å¦è¿ç»­3ä¸ªä»¥ä¸Šé«˜ä½“åŠ›æ´»åŠ¨ï¼ˆphysical.score >= 7ï¼‰
   - å¦‚æœæœ‰ï¼Œæç¤ºç”¨æˆ·ä½“åŠ›é€æ”¯é£é™©

2. **è¿ç»­é«˜å¼ºåº¦ç²¾ç¥å·¥ä½œ**
   - æ˜¯å¦è¿ç»­3ä¸ªä»¥ä¸Šé«˜ç²¾ç¥æ´»åŠ¨ï¼ˆmental.score >= 7ï¼‰
   - å¦‚æœæœ‰ï¼Œæç¤ºç”¨æˆ·ç²¾ç¥ç–²åŠ³é£é™©

3. **å•ä¸€ç»´åº¦è¿‡åº¦é›†ä¸­**
   - æ˜¯å¦å…¨å¤©éƒ½æ˜¯ä½“åŠ›æ´»ï¼Œæ²¡æœ‰è„‘åŠ›ä¼‘æ¯ï¼Ÿ
   - æ˜¯å¦å…¨å¤©éƒ½æ˜¯è„‘åŠ›å·¥ä½œï¼Œæ²¡æœ‰ä½“åŠ›æ´»åŠ¨ï¼Ÿ
   - å¦‚æœæœ‰ï¼Œå»ºè®®å¹³è¡¡æ­é…

4. **ç¼ºä¹ä¼‘æ¯æˆ–è°ƒèŠ‚**
   - é•¿æ—¶é—´å·¥ä½œåæ˜¯å¦å®‰æ’äº†ä¼‘æ¯ï¼Ÿ
   - é«˜å‹åŠ›ä»»åŠ¡åæ˜¯å¦å®‰æ’äº†æ”¾æ¾æ´»åŠ¨ï¼Ÿ

5. **æ€»ä½“è¯„ä¼°**
   - æ—¥ç¨‹å®‰æ’çš„åˆç†æ€§è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
   - ä¸»è¦é—®é¢˜æ€»ç»“
   - å…·ä½“ä¼˜åŒ–å»ºè®®

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{{
    "overall_score": 0-10çš„æ•´æ•°,
    "has_issues": true/false,
    "issues": [
        {{
            "type": "è¿ç»­ä½“åŠ›æ¶ˆè€—" | "è¿ç»­ç²¾ç¥å·¥ä½œ" | "å•ä¸€ç»´åº¦é›†ä¸­" | "ç¼ºä¹ä¼‘æ¯",
            "severity": "high" | "medium" | "low",
            "description": "é—®é¢˜æè¿°",
            "affected_events": ["äº‹ä»¶1", "äº‹ä»¶2"],
            "suggestion": "å…·ä½“å»ºè®®"
        }}
    ],
    "summary": "æ€»ä½“è¯„ä»·",
    "recommendations": ["å»ºè®®1", "å»ºè®®2"]
}}

å¦‚æœæ—¥ç¨‹å®‰æ’å¾ˆåˆç†ï¼Œhas_issues ä¸º falseï¼Œissues ä¸ºç©ºæ•°ç»„ï¼Œoverall_score >= 8ã€‚
"""

        return prompt

    def _parse_analysis(self, response: str) -> Dict[str, Any]:
        """è§£æ LLM å“åº”"""
        import json

        try:
            # æå– JSON
            if "```json" in response:
                json_str = response.split("```json")[1].split("```")[0].strip()
            elif "```" in response:
                json_str = response.split("```")[1].split("```")[0].strip()
            else:
                json_str = response.strip()

            data = json.loads(json_str)

            return {
                "success": True,
                "analysis": data,
                "message": self._format_message(data)
            }

        except Exception as e:
            print(f"[Smart Scheduler] Failed to parse response: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "æ—¥ç¨‹åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
            }

    def _format_message(self, analysis: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–åˆ†æç»“æœä¸ºç”¨æˆ·å‹å¥½çš„æ¶ˆæ¯"""

        if not analysis.get("has_issues", False):
            return f"âœ… æ—¥ç¨‹å®‰æ’åˆç†ï¼è¯„åˆ†ï¼š{analysis.get('overall_score', 8)}/10"

        issues = analysis.get("issues", [])
        message = f"âš ï¸ æ£€æµ‹åˆ°æ—¥ç¨‹å®‰æ’é—®é¢˜ï¼ˆè¯„åˆ†ï¼š{analysis.get('overall_score', 5)}/10ï¼‰\n\n"

        for i, issue in enumerate(issues, 1):
            severity_icon = {
                "high": "ğŸ”´",
                "medium": "ğŸŸ¡",
                "low": "ğŸŸ¢"
            }.get(issue.get("severity", "medium"), "âšª")

            message += f"{severity_icon} {issue.get('type', '')}: {issue.get('description', '')}\n"
            message += f"   å»ºè®®ï¼š{issue.get('suggestion', '')}\n\n"

        # æ·»åŠ æ€»ä½“å»ºè®®
        recommendations = analysis.get("recommendations", [])
        if recommendations:
            message += "ğŸ’¡ æ€»ä½“å»ºè®®ï¼š\n"
            for rec in recommendations:
                message += f"   â€¢ {rec}\n"

        return message

    async def quick_check(
        self,
        events: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        å¿«é€Ÿæ£€æŸ¥ï¼ˆä¸è°ƒç”¨ LLMï¼Œä½¿ç”¨è§„åˆ™ï¼‰

        Args:
            events: äº‹ä»¶åˆ—è¡¨

        Returns:
            å¿«é€Ÿæ£€æŸ¥ç»“æœ
        """
        issues = []

        # è§„åˆ™1ï¼šè¿ç»­é«˜ä½“åŠ›
        high_physical_count = 0
        for event in events:
            energy = event.get("energy_consumption")
            if energy and energy["physical"]["score"] >= 7:
                high_physical_count += 1
                if high_physical_count >= 3:
                    issues.append({
                        "type": "è¿ç»­ä½“åŠ›æ¶ˆè€—",
                        "severity": "high",
                        "description": f"è¿ç»­{high_physical_count}ä¸ªé«˜ä½“åŠ›æ´»åŠ¨",
                        "suggestion": "å»ºè®®åœ¨ä¸­é—´æ’å…¥ä¼‘æ¯æˆ–è½»åº¦è„‘åŠ›æ´»åŠ¨"
                    })
                    break
            else:
                high_physical_count = 0

        # è§„åˆ™2ï¼šè¿ç»­é«˜ç²¾ç¥
        high_mental_count = 0
        for event in events:
            energy = event.get("energy_consumption")
            if energy and energy["mental"]["score"] >= 7:
                high_mental_count += 1
                if high_mental_count >= 3:
                    issues.append({
                        "type": "è¿ç»­ç²¾ç¥å·¥ä½œ",
                        "severity": "high",
                        "description": f"è¿ç»­{high_mental_count}ä¸ªé«˜ç²¾ç¥æ´»åŠ¨",
                        "suggestion": "å»ºè®®åœ¨ä¸­é—´å®‰æ’ä¼‘æ¯æˆ–ä½“åŠ›æ´»åŠ¨æ”¾æ¾"
                    })
                    break
            else:
                high_mental_count = 0

        if issues:
            return {
                "success": True,
                "has_issues": True,
                "issues": issues,
                "overall_score": max(10 - len(issues) * 2, 3),
                "message": "æ£€æµ‹åˆ°æ—¥ç¨‹å®‰æ’é—®é¢˜"
            }
        else:
            return {
                "success": True,
                "has_issues": False,
                "issues": [],
                "overall_score": 9,
                "message": "æ—¥ç¨‹å®‰æ’åŸºæœ¬åˆç†"
            }


# å…¨å±€å®ä¾‹
smart_scheduler_agent = SmartSchedulerAgent()
